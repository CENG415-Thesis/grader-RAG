{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from query_data import query_rag\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert evaluator. Grade the response based on the following criteria:\n",
    "1. Groundedness: Does the response fully address the question using the provided context?\n",
    "2. Answer Relevance: Is the response relevant and directly answering the question?\n",
    "3. Context Relevance: Is the response actually correct based on the context?\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Response:\n",
    "{response}\n",
    "\n",
    "---\n",
    "\n",
    "Provide a float score from 0 to 1 for each criteria and a short explanation for the score.\n",
    "\"\"\"\n",
    "\n",
    "class Grader:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the Grader class to evaluate the responses.\n",
    "        \"\"\"\n",
    "        self.model = OllamaLLM(model=\"llama3\")  # Grading LLM\n",
    "\n",
    "    def grade(self, context: str, question: str, response: str) -> str:\n",
    "        \"\"\"\n",
    "        Grades the response based on the context and question using a prompt template.\n",
    "\n",
    "        Args:\n",
    "            context (str): The retrieved context from the database.\n",
    "            question (str): The input query text.\n",
    "            response (str): The generated response to evaluate.\n",
    "\n",
    "        Returns:\n",
    "            str: The grading result with a score and an explanation.\n",
    "        \"\"\"\n",
    "        # Prepare the grading prompt\n",
    "        prompt_template = ChatPromptTemplate.from_template(GRADER_PROMPT_TEMPLATE)\n",
    "        prompt = prompt_template.format(\n",
    "            context=context, question=question, response=response\n",
    "        )\n",
    "\n",
    "        # Invoke the grading model\n",
    "        grading_result = self.model.invoke(prompt)\n",
    "        return grading_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What modulation techniques are used in the physical layer of LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: Why is cell search necessary in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the difference between FDD and TDD modes?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "‚úÖAll processing complete. üëâüèª Results saved to 'processed_questions.json'.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_file = \"question_set.json\"\n",
    "    output_file = \"processed_questions.json\"\n",
    "        \n",
    "    # Load the question set\n",
    "    with open(input_file, \"r\") as file:\n",
    "        question_set = json.load(file)\n",
    "\n",
    "    processed_questions = []\n",
    "\n",
    "    # Process each question and store the response\n",
    "    for qa in question_set:\n",
    "        question = qa[\"question\"]\n",
    "        expected_answer = qa.get(\"answer\", \"N/A\")\n",
    "        print(f\"Processing question: {question}\")\n",
    "\n",
    "        # Query the RAG pipeline\n",
    "        llm_answer = query_rag(question)\n",
    "        \n",
    "        # Grade the response\n",
    "        grader = Grader()\n",
    "        grading_result = grader.grade(expected_answer, question, llm_answer)\n",
    "        \n",
    "        print(\"\\t o) Process and Grading of the question is complete.\")\n",
    "        \n",
    "        # Store the result\n",
    "        processed_questions.append({\n",
    "            \"question\": question,\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"llm_answer\": llm_answer,\n",
    "            \"grading_result\": grading_result\n",
    "        })\n",
    "\n",
    "    # Write the processed questions to the output file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(processed_questions, file, indent=4)\n",
    "        \n",
    "    print(f\"‚úÖAll processing complete. üëâüèª Results saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What modulation techniques are used in the physical layer of LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: Why is cell search necessary in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the difference between FDD and TDD modes?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the advantage of narrowband operation in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the purpose of Turbo Coding in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: How does MIMO provide an advantage in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: Which uplink physical channels are used in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: How does beamforming work in external antenna arrays?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is Hybrid ARQ (HARQ) in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the purpose of Multicast/Broadcast Single Frequency Network (MBSFN)?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the purpose of physical measurement reporting in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: How is narrowband operation defined in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What error control mechanism is used during channel coding in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the role of OFDM in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: Why is SC-FDMA preferred for uplink in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the function of Proximity Services (ProSe) in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What problem does Coordinated Multi-Point (CoMP) solve in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: Why are LTE physical channels divided into uplink and downlink?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: What is the purpose of uplink synchronization in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "Processing question: Which signals provide frequency and time synchronization in LTE?\n",
      "\t o) Process and Grading of the question is complete.\n",
      "‚úÖAll processing complete. üëâüèª Results saved to 'processed_questions2.json'.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_file = \"question_set2.json\"\n",
    "    output_file = \"processed_questions2.json\"\n",
    "        \n",
    "    # Load the question set\n",
    "    with open(input_file, \"r\") as file:\n",
    "        question_set = json.load(file)\n",
    "\n",
    "    processed_questions = []\n",
    "\n",
    "    # Process each question and store the response\n",
    "    for qa in question_set:\n",
    "        question = qa[\"question\"]\n",
    "        expected_answer = qa.get(\"answer\", \"N/A\")\n",
    "        print(f\"Processing question: {question}\")\n",
    "\n",
    "        # Query the RAG pipeline\n",
    "        llm_answer = query_rag(question)\n",
    "        \n",
    "        # Grade the response\n",
    "        grader = Grader()\n",
    "        grading_result = grader.grade(expected_answer, question, llm_answer)\n",
    "        \n",
    "        print(\"\\t o) Process and Grading of the question is complete.\")\n",
    "        \n",
    "        # Store the result\n",
    "        processed_questions.append({\n",
    "            \"question\": question,\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"llm_answer\": llm_answer,\n",
    "            \"grading_result\": grading_result\n",
    "        })\n",
    "\n",
    "    # Write the processed questions to the output file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(processed_questions, file, indent=4)\n",
    "        \n",
    "    print(f\"‚úÖAll processing complete. üëâüèª Results saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
